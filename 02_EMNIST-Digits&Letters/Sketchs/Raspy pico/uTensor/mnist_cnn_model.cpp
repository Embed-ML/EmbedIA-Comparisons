/* Auto-generated by utensor cli */
#include "uTensor.h"
#include "params_mnist_cnn_model.hpp"
#include "mnist_cnn_model.hpp"


Mnist_cnn_model::Mnist_cnn_model () :
op_Conv2dOperator_000({ 1, 1, 1, 1 }, VALID)
, op_DequantizeOperator_001()
, op_DepthwiseSeparableConvOperator_002({ 1, 1 }, VALID, 8, { 1, 1 }, TFLM::TfLiteFusedActivation::kTfLiteActRelu)
, op_FullyConnectedOperator_003(TFLM::TfLiteFusedActivation::kTfLiteActNone)
, op_ReshapeOperator_004({ 1, 72 })
, op_QuantizeOperator_005()
, op_MaxPoolOperator_006({ 3, 3 }, { 1, 3, 3, 1 }, VALID)
, op_ReLUOperator_007()
, op_FullyConnectedOperator_008(TFLM::TfLiteFusedActivation::kTfLiteActRelu)
{
  Context::get_default_context()->set_ram_data_allocator(&ram_allocator);
  Context::get_default_context()->set_metadata_allocator(&metadata_allocator);
  // TODO: moving ROMTensor declarations here
}

void Mnist_cnn_model::compute()
{
  // update context in case there are multiple models being run
  Context::get_default_context()->set_ram_data_allocator(&ram_allocator);
  Context::get_default_context()->set_metadata_allocator(&metadata_allocator);
  // start rendering local snippets
  Tensor t_input_1_int80 = new RamTensor({ 1, 16, 16, 1 }, i8);
    int32_t t_input_1_int80_zp = -128;
    float t_input_1_int80_scale = 0.003921569;
    PerTensorQuantizationParams t_input_1_int80_quant_params(t_input_1_int80_zp, t_input_1_int80_scale);
    t_input_1_int80->set_quantization_params(t_input_1_int80_quant_params);


  op_QuantizeOperator_005
    .set_inputs({
        { TflmSymQuantOps::QuantizeOperator<int8_t, float>::input, inputs[input_0].tensor() },
    })
    .set_outputs({
        { TflmSymQuantOps::QuantizeOperator<int8_t, float>::output, t_input_1_int80}
    })
    .eval();

  Tensor t_StatefulPartitionedCallmy_model_6conv2d_12Conv2DReadVariableOp0 = new RomTensor({ 1, 3, 3, 8 }, i8, data_StatefulPartitionedCall_my_model_6_conv2d_12_Conv2D_ReadVariableOp_0);
    int32_t arr_t_StatefulPartitionedCallmy_model_6conv2d_12Conv2DReadVariableOp0_zp[8] = { 0, 0, 0, 0, 0, 0, 0, 0 };
    float arr_t_StatefulPartitionedCallmy_model_6conv2d_12Conv2DReadVariableOp0_scale[8] = { 0.010696909, 0.0058579445, 0.005674334, 0.0070246104, 0.008616146, 0.00548731, 0.011218038, 0.00819279 };
    PerChannelQuantizationParams t_StatefulPartitionedCallmy_model_6conv2d_12Conv2DReadVariableOp0_quant_params(arr_t_StatefulPartitionedCallmy_model_6conv2d_12Conv2DReadVariableOp0_zp, arr_t_StatefulPartitionedCallmy_model_6conv2d_12Conv2DReadVariableOp0_scale);
    t_StatefulPartitionedCallmy_model_6conv2d_12Conv2DReadVariableOp0->set_quantization_params(t_StatefulPartitionedCallmy_model_6conv2d_12Conv2DReadVariableOp0_quant_params);


  Tensor t_StatefulPartitionedCallmy_model_6conv2d_12Conv2D_bias0 = new RomTensor({ 8 }, i32, data_StatefulPartitionedCall_my_model_6_conv2d_12_Conv2D_bias_0);
    int32_t arr_t_StatefulPartitionedCallmy_model_6conv2d_12Conv2D_bias0_zp[8] = { 0, 0, 0, 0, 0, 0, 0, 0 };
    float arr_t_StatefulPartitionedCallmy_model_6conv2d_12Conv2D_bias0_scale[8] = { 4.1948668e-05, 2.2972332e-05, 2.225229e-05, 2.7547494e-05, 3.378881e-05, 2.1518863e-05, 4.399231e-05, 3.2128588e-05 };
    PerChannelQuantizationParams t_StatefulPartitionedCallmy_model_6conv2d_12Conv2D_bias0_quant_params(arr_t_StatefulPartitionedCallmy_model_6conv2d_12Conv2D_bias0_zp, arr_t_StatefulPartitionedCallmy_model_6conv2d_12Conv2D_bias0_scale);
    t_StatefulPartitionedCallmy_model_6conv2d_12Conv2D_bias0->set_quantization_params(t_StatefulPartitionedCallmy_model_6conv2d_12Conv2D_bias0_quant_params);


  Tensor t_StatefulPartitionedCallmy_model_6conv2d_12Relu0 = new RamTensor({ 1, 14, 14, 8 }, i8);
    int32_t t_StatefulPartitionedCallmy_model_6conv2d_12Relu0_zp = -128;
    float t_StatefulPartitionedCallmy_model_6conv2d_12Relu0_scale = 0.009984026;
    PerTensorQuantizationParams t_StatefulPartitionedCallmy_model_6conv2d_12Relu0_quant_params(t_StatefulPartitionedCallmy_model_6conv2d_12Relu0_zp, t_StatefulPartitionedCallmy_model_6conv2d_12Relu0_scale);
    t_StatefulPartitionedCallmy_model_6conv2d_12Relu0->set_quantization_params(t_StatefulPartitionedCallmy_model_6conv2d_12Relu0_quant_params);


  op_DepthwiseSeparableConvOperator_002
    .set_inputs({
        { TflmSymQuantOps::DepthwiseSeparableConvOperator<int8_t>::in, t_input_1_int80 },
        { TflmSymQuantOps::DepthwiseSeparableConvOperator<int8_t>::filter, t_StatefulPartitionedCallmy_model_6conv2d_12Conv2DReadVariableOp0 },
        { TflmSymQuantOps::DepthwiseSeparableConvOperator<int8_t>::bias, t_StatefulPartitionedCallmy_model_6conv2d_12Conv2D_bias0 },
    })
    .set_outputs({
        { TflmSymQuantOps::DepthwiseSeparableConvOperator<int8_t>::out, t_StatefulPartitionedCallmy_model_6conv2d_12Relu0}
    })
    .eval();

  t_StatefulPartitionedCallmy_model_6conv2d_12Conv2D_bias0.free();

  t_StatefulPartitionedCallmy_model_6conv2d_12Conv2DReadVariableOp0.free();

  t_input_1_int80.free();

  Tensor t_StatefulPartitionedCallmy_model_6max_pooling2d_6MaxPool0 = new RamTensor({ 1, 4, 4, 8 }, i8);
    int32_t t_StatefulPartitionedCallmy_model_6max_pooling2d_6MaxPool0_zp = -128;
    float t_StatefulPartitionedCallmy_model_6max_pooling2d_6MaxPool0_scale = 0.009984026;
    PerTensorQuantizationParams t_StatefulPartitionedCallmy_model_6max_pooling2d_6MaxPool0_quant_params(t_StatefulPartitionedCallmy_model_6max_pooling2d_6MaxPool0_zp, t_StatefulPartitionedCallmy_model_6max_pooling2d_6MaxPool0_scale);
    t_StatefulPartitionedCallmy_model_6max_pooling2d_6MaxPool0->set_quantization_params(t_StatefulPartitionedCallmy_model_6max_pooling2d_6MaxPool0_quant_params);


  op_MaxPoolOperator_006
    .set_inputs({
        { ReferenceOperators::MaxPoolOperator<int8_t>::in, t_StatefulPartitionedCallmy_model_6conv2d_12Relu0 },
    })
    .set_outputs({
        { ReferenceOperators::MaxPoolOperator<int8_t>::out, t_StatefulPartitionedCallmy_model_6max_pooling2d_6MaxPool0}
    })
    .eval();

  t_StatefulPartitionedCallmy_model_6conv2d_12Relu0.free();

  Tensor t_StatefulPartitionedCallmy_model_6conv2d_13Conv2DReadVariableOp0 = new RomTensor({ 8, 2, 2, 8 }, i8, data_StatefulPartitionedCall_my_model_6_conv2d_13_Conv2D_ReadVariableOp_0);
    int32_t arr_t_StatefulPartitionedCallmy_model_6conv2d_13Conv2DReadVariableOp0_zp[8] = { 0, 0, 0, 0, 0, 0, 0, 0 };
    float arr_t_StatefulPartitionedCallmy_model_6conv2d_13Conv2DReadVariableOp0_scale[8] = { 0.008483202, 0.0076402426, 0.0070689796, 0.010856023, 0.00672042, 0.006039206, 0.008295754, 0.006927013 };
    PerChannelQuantizationParams t_StatefulPartitionedCallmy_model_6conv2d_13Conv2DReadVariableOp0_quant_params(arr_t_StatefulPartitionedCallmy_model_6conv2d_13Conv2DReadVariableOp0_zp, arr_t_StatefulPartitionedCallmy_model_6conv2d_13Conv2DReadVariableOp0_scale);
    t_StatefulPartitionedCallmy_model_6conv2d_13Conv2DReadVariableOp0->set_quantization_params(t_StatefulPartitionedCallmy_model_6conv2d_13Conv2DReadVariableOp0_quant_params);


  Tensor t_StatefulPartitionedCallmy_model_6conv2d_13Conv2D_bias0 = new RomTensor({ 8 }, i32, data_StatefulPartitionedCall_my_model_6_conv2d_13_Conv2D_bias_0);
    int32_t arr_t_StatefulPartitionedCallmy_model_6conv2d_13Conv2D_bias0_zp[8] = { 0, 0, 0, 0, 0, 0, 0, 0 };
    float arr_t_StatefulPartitionedCallmy_model_6conv2d_13Conv2D_bias0_scale[8] = { 8.469651e-05, 7.6280376e-05, 7.0576876e-05, 0.00010838681, 6.7096844e-05, 6.0295588e-05, 8.282502e-05, 6.9159476e-05 };
    PerChannelQuantizationParams t_StatefulPartitionedCallmy_model_6conv2d_13Conv2D_bias0_quant_params(arr_t_StatefulPartitionedCallmy_model_6conv2d_13Conv2D_bias0_zp, arr_t_StatefulPartitionedCallmy_model_6conv2d_13Conv2D_bias0_scale);
    t_StatefulPartitionedCallmy_model_6conv2d_13Conv2D_bias0->set_quantization_params(t_StatefulPartitionedCallmy_model_6conv2d_13Conv2D_bias0_quant_params);


  Tensor t_StatefulPartitionedCallmy_model_6conv2d_13Relu0 = new RamTensor({ 1, 3, 3, 8 }, i8);
    int32_t t_StatefulPartitionedCallmy_model_6conv2d_13Relu0_zp = -128;
    float t_StatefulPartitionedCallmy_model_6conv2d_13Relu0_scale = 0.030206751;
    PerTensorQuantizationParams t_StatefulPartitionedCallmy_model_6conv2d_13Relu0_quant_params(t_StatefulPartitionedCallmy_model_6conv2d_13Relu0_zp, t_StatefulPartitionedCallmy_model_6conv2d_13Relu0_scale);
    t_StatefulPartitionedCallmy_model_6conv2d_13Relu0->set_quantization_params(t_StatefulPartitionedCallmy_model_6conv2d_13Relu0_quant_params);


  op_Conv2dOperator_000
    .set_inputs({
        { ReferenceOperators::Conv2dOperator<int8_t>::in, t_StatefulPartitionedCallmy_model_6max_pooling2d_6MaxPool0 },
        { ReferenceOperators::Conv2dOperator<int8_t>::filter, t_StatefulPartitionedCallmy_model_6conv2d_13Conv2DReadVariableOp0 },
    })
    .set_outputs({
        { ReferenceOperators::Conv2dOperator<int8_t>::out, t_StatefulPartitionedCallmy_model_6conv2d_13Relu0}
    })
    .eval();

  t_StatefulPartitionedCallmy_model_6max_pooling2d_6MaxPool0.free();

  t_StatefulPartitionedCallmy_model_6conv2d_13Conv2D_bias0.free();

  t_StatefulPartitionedCallmy_model_6conv2d_13Conv2DReadVariableOp0.free();

  Tensor t_3_CONV_2DReLU0 = new RamTensor({ 1, 3, 3, 8 }, i8);
    int32_t t_3_CONV_2DReLU0_zp = -128;
    float t_3_CONV_2DReLU0_scale = 0.030206751;
    PerTensorQuantizationParams t_3_CONV_2DReLU0_quant_params(t_3_CONV_2DReLU0_zp, t_3_CONV_2DReLU0_scale);
    t_3_CONV_2DReLU0->set_quantization_params(t_3_CONV_2DReLU0_quant_params);


  op_ReLUOperator_007
    .set_inputs({
        { ReferenceOperators::ReLUOperator<int8_t>::in, t_StatefulPartitionedCallmy_model_6conv2d_13Relu0 },
    })
    .set_outputs({
        { ReferenceOperators::ReLUOperator<int8_t>::out, t_3_CONV_2DReLU0}
    })
    .eval();

  t_StatefulPartitionedCallmy_model_6conv2d_13Relu0.free();

  Tensor t_StatefulPartitionedCallmy_model_6conv2d_13Relu_0_Reshape00 = new RamTensor({ 1, 72 }, i8);
    int32_t t_StatefulPartitionedCallmy_model_6conv2d_13Relu_0_Reshape00_zp = -128;
    float t_StatefulPartitionedCallmy_model_6conv2d_13Relu_0_Reshape00_scale = 0.030206751;
    PerTensorQuantizationParams t_StatefulPartitionedCallmy_model_6conv2d_13Relu_0_Reshape00_quant_params(t_StatefulPartitionedCallmy_model_6conv2d_13Relu_0_Reshape00_zp, t_StatefulPartitionedCallmy_model_6conv2d_13Relu_0_Reshape00_scale);
    t_StatefulPartitionedCallmy_model_6conv2d_13Relu_0_Reshape00->set_quantization_params(t_StatefulPartitionedCallmy_model_6conv2d_13Relu_0_Reshape00_quant_params);


  op_ReshapeOperator_004
    .set_inputs({
        { ReferenceOperators::ReshapeOperator<int8_t>::input, t_3_CONV_2DReLU0 },
    })
    .set_outputs({
        { ReferenceOperators::ReshapeOperator<int8_t>::output, t_StatefulPartitionedCallmy_model_6conv2d_13Relu_0_Reshape00}
    })
    .eval();

  t_3_CONV_2DReLU0.free();

  Tensor t_StatefulPartitionedCallmy_model_6dense_12MatMulReadVariableOptranspose0 = new RomTensor({ 72, 40 }, i8, data_StatefulPartitionedCall_my_model_6_dense_12_MatMul_ReadVariableOp_transpose_0);
    int32_t t_StatefulPartitionedCallmy_model_6dense_12MatMulReadVariableOptranspose0_zp = 0;
    float t_StatefulPartitionedCallmy_model_6dense_12MatMulReadVariableOptranspose0_scale = 0.008969282;
    PerTensorQuantizationParams t_StatefulPartitionedCallmy_model_6dense_12MatMulReadVariableOptranspose0_quant_params(t_StatefulPartitionedCallmy_model_6dense_12MatMulReadVariableOptranspose0_zp, t_StatefulPartitionedCallmy_model_6dense_12MatMulReadVariableOptranspose0_scale);
    t_StatefulPartitionedCallmy_model_6dense_12MatMulReadVariableOptranspose0->set_quantization_params(t_StatefulPartitionedCallmy_model_6dense_12MatMulReadVariableOptranspose0_quant_params);


  Tensor t_StatefulPartitionedCallmy_model_6dense_12MatMul_bias0 = new RomTensor({ 40 }, i32, data_StatefulPartitionedCall_my_model_6_dense_12_MatMul_bias_0);
    int32_t t_StatefulPartitionedCallmy_model_6dense_12MatMul_bias0_zp = 0;
    float t_StatefulPartitionedCallmy_model_6dense_12MatMul_bias0_scale = 0.00027093285;
    PerTensorQuantizationParams t_StatefulPartitionedCallmy_model_6dense_12MatMul_bias0_quant_params(t_StatefulPartitionedCallmy_model_6dense_12MatMul_bias0_zp, t_StatefulPartitionedCallmy_model_6dense_12MatMul_bias0_scale);
    t_StatefulPartitionedCallmy_model_6dense_12MatMul_bias0->set_quantization_params(t_StatefulPartitionedCallmy_model_6dense_12MatMul_bias0_quant_params);


  Tensor t_StatefulPartitionedCallmy_model_6dense_12Relu0 = new RamTensor({ 1, 40 }, i8);
    int32_t t_StatefulPartitionedCallmy_model_6dense_12Relu0_zp = -128;
    float t_StatefulPartitionedCallmy_model_6dense_12Relu0_scale = 0.07204303;
    PerTensorQuantizationParams t_StatefulPartitionedCallmy_model_6dense_12Relu0_quant_params(t_StatefulPartitionedCallmy_model_6dense_12Relu0_zp, t_StatefulPartitionedCallmy_model_6dense_12Relu0_scale);
    t_StatefulPartitionedCallmy_model_6dense_12Relu0->set_quantization_params(t_StatefulPartitionedCallmy_model_6dense_12Relu0_quant_params);


  op_FullyConnectedOperator_008
    .set_inputs({
        { TflmSymQuantOps::FullyConnectedOperator<int8_t>::input, t_StatefulPartitionedCallmy_model_6conv2d_13Relu_0_Reshape00 },
        { TflmSymQuantOps::FullyConnectedOperator<int8_t>::filter, t_StatefulPartitionedCallmy_model_6dense_12MatMulReadVariableOptranspose0 },
        { TflmSymQuantOps::FullyConnectedOperator<int8_t>::bias, t_StatefulPartitionedCallmy_model_6dense_12MatMul_bias0 },
    })
    .set_outputs({
        { TflmSymQuantOps::FullyConnectedOperator<int8_t>::output, t_StatefulPartitionedCallmy_model_6dense_12Relu0}
    })
    .eval();

  t_StatefulPartitionedCallmy_model_6dense_12MatMulReadVariableOptranspose0.free();

  t_StatefulPartitionedCallmy_model_6dense_12MatMul_bias0.free();

  t_StatefulPartitionedCallmy_model_6conv2d_13Relu_0_Reshape00.free();

  Tensor t_StatefulPartitionedCallmy_model_6dense_13MatMulReadVariableOptranspose0 = new RomTensor({ 40, 36 }, i8, data_StatefulPartitionedCall_my_model_6_dense_13_MatMul_ReadVariableOp_transpose_0);
    int32_t t_StatefulPartitionedCallmy_model_6dense_13MatMulReadVariableOptranspose0_zp = 0;
    float t_StatefulPartitionedCallmy_model_6dense_13MatMulReadVariableOptranspose0_scale = 0.010233552;
    PerTensorQuantizationParams t_StatefulPartitionedCallmy_model_6dense_13MatMulReadVariableOptranspose0_quant_params(t_StatefulPartitionedCallmy_model_6dense_13MatMulReadVariableOptranspose0_zp, t_StatefulPartitionedCallmy_model_6dense_13MatMulReadVariableOptranspose0_scale);
    t_StatefulPartitionedCallmy_model_6dense_13MatMulReadVariableOptranspose0->set_quantization_params(t_StatefulPartitionedCallmy_model_6dense_13MatMulReadVariableOptranspose0_quant_params);


  Tensor t_StatefulPartitionedCallmy_model_6dense_13MatMul_bias0 = new RomTensor({ 36 }, i32, data_StatefulPartitionedCall_my_model_6_dense_13_MatMul_bias_0);
    int32_t t_StatefulPartitionedCallmy_model_6dense_13MatMul_bias0_zp = 0;
    float t_StatefulPartitionedCallmy_model_6dense_13MatMul_bias0_scale = 0.00073725614;
    PerTensorQuantizationParams t_StatefulPartitionedCallmy_model_6dense_13MatMul_bias0_quant_params(t_StatefulPartitionedCallmy_model_6dense_13MatMul_bias0_zp, t_StatefulPartitionedCallmy_model_6dense_13MatMul_bias0_scale);
    t_StatefulPartitionedCallmy_model_6dense_13MatMul_bias0->set_quantization_params(t_StatefulPartitionedCallmy_model_6dense_13MatMul_bias0_quant_params);


  Tensor t_Identity_int80 = new RamTensor({ 1, 36 }, i8);
    int32_t t_Identity_int80_zp = 31;
    float t_Identity_int80_scale = 0.23988324;
    PerTensorQuantizationParams t_Identity_int80_quant_params(t_Identity_int80_zp, t_Identity_int80_scale);
    t_Identity_int80->set_quantization_params(t_Identity_int80_quant_params);


  op_FullyConnectedOperator_003
    .set_inputs({
        { TflmSymQuantOps::FullyConnectedOperator<int8_t>::input, t_StatefulPartitionedCallmy_model_6dense_12Relu0 },
        { TflmSymQuantOps::FullyConnectedOperator<int8_t>::filter, t_StatefulPartitionedCallmy_model_6dense_13MatMulReadVariableOptranspose0 },
        { TflmSymQuantOps::FullyConnectedOperator<int8_t>::bias, t_StatefulPartitionedCallmy_model_6dense_13MatMul_bias0 },
    })
    .set_outputs({
        { TflmSymQuantOps::FullyConnectedOperator<int8_t>::output, t_Identity_int80}
    })
    .eval();

  t_StatefulPartitionedCallmy_model_6dense_13MatMulReadVariableOptranspose0.free();

  t_StatefulPartitionedCallmy_model_6dense_13MatMul_bias0.free();

  t_StatefulPartitionedCallmy_model_6dense_12Relu0.free();

  op_DequantizeOperator_001
    .set_inputs({
        { TflmSymQuantOps::DequantizeOperator<float, int8_t>::a, t_Identity_int80 },
    })
    .set_outputs({
        { TflmSymQuantOps::DequantizeOperator<float, int8_t>::b, outputs[output_0].tensor()}
    })
    .eval();

  t_Identity_int80.free();
  // end of rendering local snippets
}
